{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MorphoDiff 完整流程：从预处理到训练到推理\n",
    "\n",
    "本笔记本包含了 MorphoDiff 的完整流程，包括：\n",
    "1. 环境设置和依赖安装\n",
    "2. 数据预处理\n",
    "3. 扰动编码（Perturbation Encoding）\n",
    "4. 模型训练\n",
    "5. 图像生成和推理\n",
    "6. 结果评估\n",
    "\n",
    "MorphoDiff 是一个基于扩散模型的生成管道，能够基于扰动编码预测不同条件下的高分辨率细胞形态响应。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 环境设置和依赖安装"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 检查CUDA可用性\n",
    "import torch\n",
    "import os\n",
    "import sys\n",
    "\n",
    "print(f\"Python 版本: {sys.version}\")\n",
    "print(f\"PyTorch 版本: {torch.__version__}\")\n",
    "print(f\"CUDA 可用: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA 设备数量: {torch.cuda.device_count()}\")\n",
    "    print(f\"当前CUDA设备: {torch.cuda.current_device()}\")\n",
    "    print(f\"设备名称: {torch.cuda.get_device_name()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 安装必要的包（如果尚未安装）\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "def install_package(package):\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package])\n",
    "\n",
    "# 基础依赖\n",
    "packages = [\n",
    "    \"accelerate\",\n",
    "    \"diffusers\",\n",
    "    \"transformers\",\n",
    "    \"datasets\",\n",
    "    \"wandb\",\n",
    "    \"Pillow\",\n",
    "    \"numpy\",\n",
    "    \"pandas\",\n",
    "    \"torch\",\n",
    "    \"torchvision\",\n",
    "    \"tqdm\",\n",
    "    \"matplotlib\",\n",
    "    \"seaborn\"\n",
    "]\n",
    "\n",
    "print(\"检查并安装必要的包...\")\n",
    "for package in packages:\n",
    "    try:\n",
    "        __import__(package.replace(\"-\", \"_\"))\n",
    "        print(f\"✓ {package} 已安装\")\n",
    "    except ImportError:\n",
    "        print(f\"安装 {package}...\")\n",
    "        install_package(package)\n",
    "        print(f\"✓ {package} 安装完成\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入所有必要的库\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import math\n",
    "import time\n",
    "import shutil\n",
    "import argparse\n",
    "import subprocess\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from typing import Optional\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# Diffusers和HuggingFace库\n",
    "from diffusers import (\n",
    "    AutoencoderKL, \n",
    "    DDPMScheduler, \n",
    "    StableDiffusionPipeline, \n",
    "    UNet2DConditionModel\n",
    ")\n",
    "from diffusers.optimization import get_scheduler\n",
    "from transformers import AutoFeatureExtractor\n",
    "from datasets import load_dataset\n",
    "from accelerate import Accelerator\n",
    "from accelerate.utils import set_seed\n",
    "\n",
    "# 设置随机种子\n",
    "set_seed(42)\n",
    "\n",
    "print(\"所有库导入成功！\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 配置路径和参数\n",
    "\n",
    "在这里设置所有重要的路径和参数。根据您的具体设置调整这些路径。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== 配置参数 =====\n",
    "# 根据您的环境调整这些路径\n",
    "\n",
    "# 基础路径配置\n",
    "PROJECT_ROOT = \"/home/runner/work/MorphoDiff/MorphoDiff\"  # 项目根目录\n",
    "MORPHODIFF_ROOT = os.path.join(PROJECT_ROOT, \"morphodiff\")  # morphodiff 代码目录\n",
    "\n",
    "# 数据路径（需要根据实际情况调整）\n",
    "DATA_ROOT = \"/tmp/morphodiff_data\"  # 临时数据目录\n",
    "DATASET_NAME = \"BBBC021\"  # 数据集名称\n",
    "TRAIN_DATA_DIR = os.path.join(DATA_ROOT, f\"{DATASET_NAME}/train_imgs/\")  # 训练数据目录\n",
    "\n",
    "# 模型和检查点路径\n",
    "MODEL_CHECKPOINTS_DIR = os.path.join(DATA_ROOT, \"checkpoints\")\n",
    "PRETRAINED_MODEL = \"CompVis/stable-diffusion-v1-4\"  # 预训练模型\n",
    "OUTPUT_DIR = os.path.join(MODEL_CHECKPOINTS_DIR, f\"{DATASET_NAME}-MorphoDiff\")\n",
    "\n",
    "# 生成图像输出路径\n",
    "GENERATED_IMAGES_DIR = os.path.join(DATA_ROOT, f\"{DATASET_NAME}/generated_imgs/\")\n",
    "\n",
    "# 日志路径\n",
    "LOG_DIR = os.path.join(DATA_ROOT, \"logs\")\n",
    "\n",
    "# 创建必要的目录\n",
    "os.makedirs(DATA_ROOT, exist_ok=True)\n",
    "os.makedirs(TRAIN_DATA_DIR, exist_ok=True)\n",
    "os.makedirs(MODEL_CHECKPOINTS_DIR, exist_ok=True)\n",
    "os.makedirs(GENERATED_IMAGES_DIR, exist_ok=True)\n",
    "os.makedirs(LOG_DIR, exist_ok=True)\n",
    "\n",
    "# 训练参数\n",
    "TRAINING_CONFIG = {\n",
    "    \"resolution\": 512,\n",
    "    \"train_batch_size\": 4,  # 根据GPU内存调整\n",
    "    \"gradient_accumulation_steps\": 8,\n",
    "    \"max_train_steps\": 500,  # 演示用的较小步数\n",
    "    \"learning_rate\": 1e-5,\n",
    "    \"lr_scheduler\": \"constant\",\n",
    "    \"lr_warmup_steps\": 0,\n",
    "    \"validation_epochs\": 50,\n",
    "    \"checkpointing_steps\": 100,\n",
    "    \"seed\": 42\n",
    "}\n",
    "\n",
    "# 验证的扰动ID\n",
    "VALIDATION_PROMPTS = [\"cytochalasin-d\", \"docetaxel\", \"epothilone-b\"]\n",
    "\n",
    "print(f\"项目根目录: {PROJECT_ROOT}\")\n",
    "print(f\"数据目录: {DATA_ROOT}\")\n",
    "print(f\"训练数据目录: {TRAIN_DATA_DIR}\")\n",
    "print(f\"输出目录: {OUTPUT_DIR}\")\n",
    "print(f\"生成图像目录: {GENERATED_IMAGES_DIR}\")\n",
    "print(\"\\n配置完成！\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 数据预处理\n",
    "\n",
    "这一部分演示如何准备数据，包括图像预处理和创建 metadata.jsonl 文件。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建示例数据集结构\n",
    "# 在实际使用中，您需要从 BBBC021、RxRx1 或其他数据集下载真实数据\n",
    "\n",
    "def create_sample_dataset():\n",
    "    \"\"\"创建示例数据集用于演示\"\"\"\n",
    "    \n",
    "    # 创建一些示例图像\n",
    "    sample_compounds = [\n",
    "        \"cytochalasin-d\", \"docetaxel\", \"epothilone-b\", \n",
    "        \"camptothecin\", \"taxol\", \"leupeptin\"\n",
    "    ]\n",
    "    \n",
    "    metadata_entries = []\n",
    "    \n",
    "    for i, compound in enumerate(sample_compounds):\n",
    "        # 创建示例图像（实际使用中应该是真实的细胞图像）\n",
    "        for j in range(3):  # 每个化合物3张图像\n",
    "            # 生成随机彩色图像作为示例\n",
    "            image_data = np.random.randint(0, 256, (512, 512, 3), dtype=np.uint8)\n",
    "            image = Image.fromarray(image_data)\n",
    "            \n",
    "            # 保存图像\n",
    "            image_filename = f\"{compound}_{j:03d}.png\"\n",
    "            image_path = os.path.join(TRAIN_DATA_DIR, image_filename)\n",
    "            image.save(image_path)\n",
    "            \n",
    "            # 创建metadata条目\n",
    "            metadata_entry = {\n",
    "                \"file_name\": image_filename,\n",
    "                \"additional_feature\": compound,  # 扰动ID\n",
    "                \"image\": image_filename\n",
    "            }\n",
    "            metadata_entries.append(metadata_entry)\n",
    "    \n",
    "    # 保存metadata.jsonl文件\n",
    "    metadata_path = os.path.join(TRAIN_DATA_DIR, \"metadata.jsonl\")\n",
    "    with open(metadata_path, 'w') as f:\n",
    "        for entry in metadata_entries:\n",
    "            f.write(json.dumps(entry) + '\\n')\n",
    "    \n",
    "    print(f\"创建了 {len(metadata_entries)} 个训练样本\")\n",
    "    print(f\"图像保存在: {TRAIN_DATA_DIR}\")\n",
    "    print(f\"元数据保存在: {metadata_path}\")\n",
    "    \n",
    "    return metadata_entries\n",
    "\n",
    "# 创建示例数据集\n",
    "sample_metadata = create_sample_dataset()\n",
    "\n",
    "# 显示数据集信息\n",
    "print(\"\\n数据集信息:\")\n",
    "df = pd.DataFrame(sample_metadata)\n",
    "print(df.groupby('additional_feature').size())\n",
    "print(f\"\\n总共 {len(df)} 张图像\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 验证数据集格式\n",
    "def verify_dataset_format(data_dir):\n",
    "    \"\"\"验证数据集格式是否符合要求\"\"\"\n",
    "    \n",
    "    metadata_path = os.path.join(data_dir, \"metadata.jsonl\")\n",
    "    \n",
    "    if not os.path.exists(metadata_path):\n",
    "        print(\"❌ metadata.jsonl 文件不存在\")\n",
    "        return False\n",
    "    \n",
    "    # 读取metadata\n",
    "    metadata = []\n",
    "    with open(metadata_path, 'r') as f:\n",
    "        for line in f:\n",
    "            metadata.append(json.loads(line.strip()))\n",
    "    \n",
    "    print(f\"✓ 找到 {len(metadata)} 个元数据条目\")\n",
    "    \n",
    "    # 检查必需的字段\n",
    "    required_fields = ['file_name', 'additional_feature', 'image']\n",
    "    for field in required_fields:\n",
    "        if field not in metadata[0]:\n",
    "            print(f\"❌ 缺少必需字段: {field}\")\n",
    "            return False\n",
    "        print(f\"✓ 找到字段: {field}\")\n",
    "    \n",
    "    # 检查图像文件是否存在\n",
    "    missing_files = 0\n",
    "    for entry in metadata[:5]:  # 只检查前5个文件\n",
    "        image_path = os.path.join(data_dir, entry['file_name'])\n",
    "        if not os.path.exists(image_path):\n",
    "            missing_files += 1\n",
    "    \n",
    "    if missing_files > 0:\n",
    "        print(f\"❌ 发现 {missing_files} 个缺失的图像文件\")\n",
    "        return False\n",
    "    \n",
    "    print(\"✓ 图像文件检查通过\")\n",
    "    \n",
    "    # 显示扰动分布\n",
    "    perturbations = [entry['additional_feature'] for entry in metadata]\n",
    "    perturbation_counts = pd.Series(perturbations).value_counts()\n",
    "    print(f\"\\n扰动分布:\")\n",
    "    print(perturbation_counts)\n",
    "    \n",
    "    return True\n",
    "\n",
    "# 验证数据集\n",
    "is_valid = verify_dataset_format(TRAIN_DATA_DIR)\n",
    "print(f\"\\n数据集格式验证: {'✓ 通过' if is_valid else '❌ 失败'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 扰动编码（Perturbation Encoding）\n",
    "\n",
    "这一部分处理扰动编码，包括化学化合物和基因扰动的编码。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 复制扰动编码器\n",
    "perturbation_encoder_path = os.path.join(MORPHODIFF_ROOT, \"perturbation_encoder.py\")\n",
    "local_perturbation_encoder = os.path.join(DATA_ROOT, \"perturbation_encoder.py\")\n",
    "\n",
    "# 复制文件到工作目录\n",
    "shutil.copy2(perturbation_encoder_path, local_perturbation_encoder)\n",
    "\n",
    "# 复制required_file目录\n",
    "required_files_src = os.path.join(MORPHODIFF_ROOT, \"required_file\")\n",
    "required_files_dst = os.path.join(DATA_ROOT, \"required_file\")\n",
    "\n",
    "if os.path.exists(required_files_src):\n",
    "    shutil.copytree(required_files_src, required_files_dst, dirs_exist_ok=True)\n",
    "    print(\"✓ 复制了扰动编码文件\")\n",
    "else:\n",
    "    print(\"❌ 找不到required_file目录\")\n",
    "\n",
    "# 将工作目录添加到Python路径\n",
    "sys.path.insert(0, DATA_ROOT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建示例扰动编码文件\n",
    "def create_sample_perturbation_embeddings():\n",
    "    \"\"\"创建示例扰动编码文件\"\"\"\n",
    "    \n",
    "    # 示例化合物\n",
    "    compounds = [\n",
    "        \"cytochalasin-d\", \"docetaxel\", \"epothilone-b\", \n",
    "        \"camptothecin\", \"taxol\", \"leupeptin\"\n",
    "    ]\n",
    "    \n",
    "    # 生成随机嵌入向量（实际使用中应该使用RDKit等工具生成真实的化学特征）\n",
    "    embedding_dim = 200  # 嵌入维度\n",
    "    \n",
    "    # 创建DataFrame\n",
    "    data = {\"compound\": compounds}\n",
    "    \n",
    "    # 添加潜在变量列\n",
    "    for i in range(1, embedding_dim + 1):\n",
    "        # 生成随机嵌入（实际应该是有意义的化学特征）\n",
    "        data[f\"latent_{i}\"] = np.random.randn(len(compounds))\n",
    "    \n",
    "    df = pd.DataFrame(data)\n",
    "    \n",
    "    # 保存文件\n",
    "    embedding_file = os.path.join(required_files_dst, \"perturbation_embedding_bbbc021.csv\")\n",
    "    df.to_csv(embedding_file, index=False)\n",
    "    \n",
    "    print(f\"✓ 创建了扰动编码文件: {embedding_file}\")\n",
    "    print(f\"包含 {len(compounds)} 个化合物，每个有 {embedding_dim} 维特征\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "# 创建示例编码\n",
    "embedding_df = create_sample_perturbation_embeddings()\n",
    "print(\"\\n前几行编码数据:\")\n",
    "print(embedding_df.iloc[:3, :6])  # 显示前3行和前6列"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建扰动列表文件（用于推理）\n",
    "def create_perturbation_list():\n",
    "    \"\"\"创建扰动列表文件用于图像生成\"\"\"\n",
    "    \n",
    "    compounds = [\n",
    "        \"cytochalasin-d\", \"docetaxel\", \"epothilone-b\", \n",
    "        \"camptothecin\", \"taxol\", \"leupeptin\"\n",
    "    ]\n",
    "    \n",
    "    # 创建扰动信息DataFrame\n",
    "    perturbation_data = {\n",
    "        \"perturbation\": compounds,\n",
    "        \"ood\": [False] * len(compounds)  # 假设都不是out-of-distribution\n",
    "    }\n",
    "    \n",
    "    df = pd.DataFrame(perturbation_data)\n",
    "    \n",
    "    # 保存文件\n",
    "    pert_list_file = os.path.join(required_files_dst, f\"{DATASET_NAME}_pert_ood_info.csv\")\n",
    "    df.to_csv(pert_list_file, index=False)\n",
    "    \n",
    "    print(f\"✓ 创建了扰动列表文件: {pert_list_file}\")\n",
    "    print(df)\n",
    "    \n",
    "    return pert_list_file\n",
    "\n",
    "# 创建扰动列表\n",
    "perturbation_list_file = create_perturbation_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 模型训练\n",
    "\n",
    "这一部分演示如何配置和启动MorphoDiff的训练过程。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建训练配置\n",
    "def create_training_config():\n",
    "    \"\"\"创建训练配置文件\"\"\"\n",
    "    \n",
    "    config = {\n",
    "        # 模型配置\n",
    "        \"pretrained_model_name_or_path\": PRETRAINED_MODEL,\n",
    "        \"naive_conditional\": \"conditional\",  # MorphoDiff使用条件生成\n",
    "        \n",
    "        # 数据配置\n",
    "        \"train_data_dir\": TRAIN_DATA_DIR,\n",
    "        \"dataset_id\": DATASET_NAME,\n",
    "        \"image_column\": \"image\",\n",
    "        \"caption_column\": \"additional_feature\",\n",
    "        \n",
    "        # 训练配置\n",
    "        \"resolution\": TRAINING_CONFIG[\"resolution\"],\n",
    "        \"train_batch_size\": TRAINING_CONFIG[\"train_batch_size\"],\n",
    "        \"gradient_accumulation_steps\": TRAINING_CONFIG[\"gradient_accumulation_steps\"],\n",
    "        \"max_train_steps\": TRAINING_CONFIG[\"max_train_steps\"],\n",
    "        \"learning_rate\": TRAINING_CONFIG[\"learning_rate\"],\n",
    "        \"lr_scheduler\": TRAINING_CONFIG[\"lr_scheduler\"],\n",
    "        \"lr_warmup_steps\": TRAINING_CONFIG[\"lr_warmup_steps\"],\n",
    "        \n",
    "        # 验证和保存\n",
    "        \"validation_epochs\": TRAINING_CONFIG[\"validation_epochs\"],\n",
    "        \"validation_prompts\": \",\".join(VALIDATION_PROMPTS),\n",
    "        \"checkpointing_steps\": TRAINING_CONFIG[\"checkpointing_steps\"],\n",
    "        \"output_dir\": OUTPUT_DIR,\n",
    "        \n",
    "        # 其他配置\n",
    "        \"enable_xformers_memory_efficient_attention\": True,\n",
    "        \"random_flip\": True,\n",
    "        \"use_ema\": True,\n",
    "        \"gradient_checkpointing\": True,\n",
    "        \"mixed_precision\": \"fp16\",\n",
    "        \"seed\": TRAINING_CONFIG[\"seed\"],\n",
    "        \"logging_dir\": LOG_DIR,\n",
    "        \"report_to\": None,  # 不使用wandb以简化演示\n",
    "    }\n",
    "    \n",
    "    return config\n",
    "\n",
    "training_config = create_training_config()\n",
    "print(\"训练配置:\")\n",
    "for key, value in training_config.items():\n",
    "    print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建训练脚本调用函数\n",
    "def run_training(config, dry_run=True):\n",
    "    \"\"\"运行训练脚本\"\"\"\n",
    "    \n",
    "    # 构建训练命令\n",
    "    train_script = os.path.join(MORPHODIFF_ROOT, \"train.py\")\n",
    "    \n",
    "    cmd = [\n",
    "        \"accelerate\", \"launch\", \n",
    "        \"--mixed_precision=fp16\",\n",
    "        train_script\n",
    "    ]\n",
    "    \n",
    "    # 添加所有配置参数\n",
    "    for key, value in config.items():\n",
    "        if isinstance(value, bool):\n",
    "            if value:\n",
    "                cmd.append(f\"--{key}\")\n",
    "        else:\n",
    "            cmd.extend([f\"--{key}\", str(value)])\n",
    "    \n",
    "    print(\"训练命令:\")\n",
    "    print(\" \".join(cmd))\n",
    "    \n",
    "    if dry_run:\n",
    "        print(\"\\n这是一个演示运行（dry_run=True）。要实际运行训练，请设置 dry_run=False\")\n",
    "        print(\"注意：实际训练需要大量的计算资源和时间\")\n",
    "        return None\n",
    "    else:\n",
    "        print(\"\\n开始训练...\")\n",
    "        # 实际运行训练\n",
    "        try:\n",
    "            result = subprocess.run(cmd, capture_output=True, text=True, cwd=DATA_ROOT)\n",
    "            if result.returncode == 0:\n",
    "                print(\"训练完成！\")\n",
    "                print(result.stdout)\n",
    "            else:\n",
    "                print(\"训练出错：\")\n",
    "                print(result.stderr)\n",
    "            return result\n",
    "        except Exception as e:\n",
    "            print(f\"运行训练时出错: {e}\")\n",
    "            return None\n",
    "\n",
    "# 演示训练调用（不实际运行）\n",
    "result = run_training(training_config, dry_run=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. 模型推理和图像生成\n",
    "\n",
    "这一部分演示如何使用训练好的模型生成图像。在实际使用中，您需要有一个训练好的检查点。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建图像生成配置\n",
    "def create_generation_config():\n",
    "    \"\"\"创建图像生成配置\"\"\"\n",
    "    \n",
    "    config = {\n",
    "        \"experiment\": DATASET_NAME,\n",
    "        \"model_checkpoint\": OUTPUT_DIR,  # 训练后的检查点路径\n",
    "        \"model_name\": \"SD\",  # 固定为SD\n",
    "        \"model_type\": \"conditional\",  # MorphoDiff使用条件生成\n",
    "        \"vae_path\": OUTPUT_DIR,  # VAE路径\n",
    "        \"perturbation_list_address\": perturbation_list_file,\n",
    "        \"gen_img_path\": GENERATED_IMAGES_DIR,\n",
    "        \"num_imgs\": 5,  # 每个扰动生成5张图像\n",
    "        \"ood\": False\n",
    "    }\n",
    "    \n",
    "    return config\n",
    "\n",
    "generation_config = create_generation_config()\n",
    "print(\"图像生成配置:\")\n",
    "for key, value in generation_config.items():\n",
    "    print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 演示图像生成过程（使用预训练的Stable Diffusion）\n",
    "def demo_image_generation():\n",
    "    \"\"\"演示图像生成过程\"\"\"\n",
    "    \n",
    "    print(\"演示图像生成过程...\")\n",
    "    print(\"注意：这个演示使用预训练的Stable Diffusion模型\")\n",
    "    print(\"在实际使用中，您需要使用训练好的MorphoDiff检查点\")\n",
    "    \n",
    "    try:\n",
    "        # 加载预训练的Stable Diffusion管道\n",
    "        pipe = StableDiffusionPipeline.from_pretrained(\n",
    "            \"CompVis/stable-diffusion-v1-4\",\n",
    "            torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32\n",
    "        )\n",
    "        \n",
    "        if torch.cuda.is_available():\n",
    "            pipe = pipe.to(\"cuda\")\n",
    "        \n",
    "        # 生成示例图像\n",
    "        sample_prompts = [\n",
    "            \"cell morphology with cytochalasin treatment\",\n",
    "            \"cell morphology with docetaxel treatment\",\n",
    "            \"cell morphology with epothilone treatment\"\n",
    "        ]\n",
    "        \n",
    "        generated_images = []\n",
    "        \n",
    "        for i, prompt in enumerate(sample_prompts):\n",
    "            print(f\"生成图像 {i+1}/{len(sample_prompts)}: {prompt}\")\n",
    "            \n",
    "            # 生成图像\n",
    "            with torch.autocast(\"cuda\" if torch.cuda.is_available() else \"cpu\"):\n",
    "                image = pipe(prompt, num_inference_steps=20, guidance_scale=7.5).images[0]\n",
    "            \n",
    "            # 保存图像\n",
    "            image_path = os.path.join(GENERATED_IMAGES_DIR, f\"demo_{i:03d}.png\")\n",
    "            image.save(image_path)\n",
    "            generated_images.append(image)\n",
    "            \n",
    "            print(f\"✓ 保存图像: {image_path}\")\n",
    "        \n",
    "        # 显示生成的图像\n",
    "        fig, axes = plt.subplots(1, len(generated_images), figsize=(15, 5))\n",
    "        if len(generated_images) == 1:\n",
    "            axes = [axes]\n",
    "        \n",
    "        for i, (image, prompt) in enumerate(zip(generated_images, sample_prompts)):\n",
    "            axes[i].imshow(image)\n",
    "            axes[i].set_title(prompt[:30] + \"...\", fontsize=10)\n",
    "            axes[i].axis('off')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        print(\"\\n✓ 图像生成演示完成！\")\n",
    "        \n",
    "        # 清理内存\n",
    "        del pipe\n",
    "        torch.cuda.empty_cache() if torch.cuda.is_available() else None\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"图像生成演示出错: {e}\")\n",
    "        print(\"可能是由于内存不足或模型下载问题\")\n",
    "\n",
    "# 运行图像生成演示\n",
    "demo_image_generation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建图像生成脚本调用函数\n",
    "def run_image_generation(config, dry_run=True):\n",
    "    \"\"\"运行图像生成脚本\"\"\"\n",
    "    \n",
    "    # 构建生成命令\n",
    "    generation_script = os.path.join(MORPHODIFF_ROOT, \"evaluation\", \"generate_img.py\")\n",
    "    \n",
    "    cmd = [\"python\", generation_script]\n",
    "    \n",
    "    # 添加所有配置参数\n",
    "    for key, value in config.items():\n",
    "        cmd.extend([f\"--{key}\", str(value)])\n",
    "    \n",
    "    print(\"图像生成命令:\")\n",
    "    print(\" \".join(cmd))\n",
    "    \n",
    "    if dry_run:\n",
    "        print(\"\\n这是一个演示运行（dry_run=True）。要实际运行图像生成，请设置 dry_run=False\")\n",
    "        print(\"注意：实际图像生成需要训练好的MorphoDiff检查点\")\n",
    "        return None\n",
    "    else:\n",
    "        print(\"\\n开始生成图像...\")\n",
    "        # 实际运行图像生成\n",
    "        try:\n",
    "            result = subprocess.run(cmd, capture_output=True, text=True, cwd=DATA_ROOT)\n",
    "            if result.returncode == 0:\n",
    "                print(\"图像生成完成！\")\n",
    "                print(result.stdout)\n",
    "            else:\n",
    "                print(\"图像生成出错：\")\n",
    "                print(result.stderr)\n",
    "            return result\n",
    "        except Exception as e:\n",
    "            print(f\"运行图像生成时出错: {e}\")\n",
    "            return None\n",
    "\n",
    "# 演示图像生成调用（不实际运行）\n",
    "result = run_image_generation(generation_config, dry_run=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. 结果评估\n",
    "\n",
    "这一部分演示如何评估生成的图像质量。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 图像质量评估函数\n",
    "def evaluate_generated_images(image_dir):\n",
    "    \"\"\"评估生成的图像\"\"\"\n",
    "    \n",
    "    print(f\"评估目录中的图像: {image_dir}\")\n",
    "    \n",
    "    # 查找所有图像文件\n",
    "    image_files = []\n",
    "    for ext in ['*.png', '*.jpg', '*.jpeg']:\n",
    "        image_files.extend(Path(image_dir).glob(ext))\n",
    "    \n",
    "    if not image_files:\n",
    "        print(\"未找到图像文件\")\n",
    "        return\n",
    "    \n",
    "    print(f\"找到 {len(image_files)} 个图像文件\")\n",
    "    \n",
    "    # 基础统计\n",
    "    image_stats = []\n",
    "    \n",
    "    for image_path in image_files[:6]:  # 只处理前6个图像\n",
    "        try:\n",
    "            image = Image.open(image_path)\n",
    "            image_array = np.array(image)\n",
    "            \n",
    "            stats = {\n",
    "                'filename': image_path.name,\n",
    "                'size': image.size,\n",
    "                'mode': image.mode,\n",
    "                'mean_intensity': np.mean(image_array),\n",
    "                'std_intensity': np.std(image_array),\n",
    "                'min_intensity': np.min(image_array),\n",
    "                'max_intensity': np.max(image_array)\n",
    "            }\n",
    "            image_stats.append(stats)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"处理图像 {image_path} 时出错: {e}\")\n",
    "    \n",
    "    # 显示统计信息\n",
    "    if image_stats:\n",
    "        df_stats = pd.DataFrame(image_stats)\n",
    "        print(\"\\n图像统计信息:\")\n",
    "        print(df_stats)\n",
    "        \n",
    "        # 可视化图像\n",
    "        fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "        axes = axes.flatten()\n",
    "        \n",
    "        for i, image_path in enumerate(image_files[:6]):\n",
    "            try:\n",
    "                image = Image.open(image_path)\n",
    "                axes[i].imshow(image)\n",
    "                axes[i].set_title(image_path.name, fontsize=10)\n",
    "                axes[i].axis('off')\n",
    "            except Exception as e:\n",
    "                axes[i].text(0.5, 0.5, f'Error: {e}', ha='center', va='center')\n",
    "                axes[i].set_title(image_path.name, fontsize=10)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    return image_stats\n",
    "\n",
    "# 评估生成的图像\n",
    "evaluation_results = evaluate_generated_images(GENERATED_IMAGES_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. 完整流程总结\n",
    "\n",
    "这个笔记本演示了MorphoDiff的完整流程："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 流程总结\n",
    "def summarize_pipeline():\n",
    "    \"\"\"总结整个流程\"\"\"\n",
    "    \n",
    "    summary = {\n",
    "        \"1. 环境设置\": \"✓ 完成\",\n",
    "        \"2. 数据预处理\": \"✓ 完成 - 创建了示例数据集\",\n",
    "        \"3. 扰动编码\": \"✓ 完成 - 创建了示例编码文件\",\n",
    "        \"4. 模型训练\": \"演示模式 - 显示了训练命令\",\n",
    "        \"5. 图像生成\": \"✓ 完成 - 使用预训练模型演示\",\n",
    "        \"6. 结果评估\": \"✓ 完成 - 基础图像统计\"\n",
    "    }\n",
    "    \n",
    "    print(\"=\" * 50)\n",
    "    print(\"MorphoDiff 流程总结\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    for step, status in summary.items():\n",
    "        print(f\"{step}: {status}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 50)\n",
    "    print(\"下一步操作:\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    next_steps = [\n",
    "        \"1. 准备真实的细胞图像数据集 (BBBC021, RxRx1, 等)\",\n",
    "        \"2. 使用RDKit或scGPT生成真实的扰动编码\",\n",
    "        \"3. 配置accelerate（运行 'accelerate config'）\",\n",
    "        \"4. 运行完整训练（设置 dry_run=False）\",\n",
    "        \"5. 使用训练好的检查点生成图像\",\n",
    "        \"6. 使用CellProfiler进行下游分析\"\n",
    "    ]\n",
    "    \n",
    "    for step in next_steps:\n",
    "        print(step)\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 50)\n",
    "    print(\"重要文件位置:\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    important_files = {\n",
    "        \"项目根目录\": PROJECT_ROOT,\n",
    "        \"训练数据\": TRAIN_DATA_DIR,\n",
    "        \"扰动编码\": os.path.join(required_files_dst, \"perturbation_embedding_bbbc021.csv\"),\n",
    "        \"扰动列表\": perturbation_list_file,\n",
    "        \"模型输出\": OUTPUT_DIR,\n",
    "        \"生成图像\": GENERATED_IMAGES_DIR,\n",
    "        \"日志目录\": LOG_DIR\n",
    "    }\n",
    "    \n",
    "    for name, path in important_files.items():\n",
    "        exists = \"✓\" if os.path.exists(path) else \"❌\"\n",
    "        print(f\"{name}: {path} {exists}\")\n",
    "\n",
    "summarize_pipeline()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. 实际使用指南\n",
    "\n",
    "要在实际项目中使用这个流程：\n",
    "\n",
    "### 数据准备\n",
    "1. 下载真实数据集（BBBC021、RxRx1等）\n",
    "2. 按照ImageFolder格式组织数据\n",
    "3. 创建metadata.jsonl文件\n",
    "\n",
    "### 扰动编码\n",
    "1. 对于化学化合物：使用RDKit生成分子描述符\n",
    "2. 对于基因扰动：使用scGPT生成基因嵌入\n",
    "3. 将编码保存为CSV格式\n",
    "\n",
    "### 训练\n",
    "1. 配置accelerate：`accelerate config`\n",
    "2. 调整训练参数（批大小、学习率等）\n",
    "3. 运行训练脚本\n",
    "\n",
    "### 推理\n",
    "1. 使用训练好的检查点\n",
    "2. 准备扰动列表\n",
    "3. 生成图像\n",
    "\n",
    "### 评估\n",
    "1. 使用CellProfiler提取特征\n",
    "2. 计算图像质量指标\n",
    "3. 进行下游分析"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}